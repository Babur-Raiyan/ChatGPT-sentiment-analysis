{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-29T06:21:31.014716300Z",
     "start_time": "2023-12-29T06:21:30.895053300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   num_labels                                   processed_tweets\n0           1      alright ChatGPT AI pretty neat @nocontextvarg\n1           1  ok definitely go replace soon importantly chat...\n2           0  ask chatgpt explain 4 famous chess quote Timma...\n3           1                               chatgpt popular good\n4           0  write ida plugin query chatgpt explain decompi...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num_labels</th>\n      <th>processed_tweets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>alright ChatGPT AI pretty neat @nocontextvarg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>ok definitely go replace soon importantly chat...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>ask chatgpt explain 4 famous chess quote Timma...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>chatgpt popular good</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>write ida plugin query chatgpt explain decompi...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Python Codes\\Code\\Code\\ChatGPT-sentiment-analysis\\processed_file.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 2)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T05:53:04.857687200Z",
     "start_time": "2023-12-29T05:53:04.843477200Z"
    }
   },
   "id": "2f37d9c3c32e1e92"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "num_labels          0\nprocessed_tweets    8\ndtype: int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T05:53:14.988546600Z",
     "start_time": "2023-12-29T05:53:14.965644200Z"
    }
   },
   "id": "488e4dfd31b58804"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "3718"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T05:53:27.444920500Z",
     "start_time": "2023-12-29T05:53:27.401656Z"
    }
   },
   "id": "88d0b34662704201"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = df.dropna().drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T05:53:56.480282900Z",
     "start_time": "2023-12-29T05:53:56.425690700Z"
    }
   },
   "id": "b3cbc0584b7f104d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "           processed_tweets         \\\n                      count unique   \nnum_labels                           \n0                     18581  18581   \n1                     19272  19272   \n2                     18427  18427   \n\n                                                                    \n                                                          top freq  \nnum_labels                                                          \n0           ask chatgpt explain 4 famous chess quote Timma...    1  \n1               alright ChatGPT AI pretty neat @nocontextvarg    1  \n2           find Microsoft 365 answer ChatGPT successful m...    1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">processed_tweets</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n    </tr>\n    <tr>\n      <th>num_labels</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18581</td>\n      <td>18581</td>\n      <td>ask chatgpt explain 4 famous chess quote Timma...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19272</td>\n      <td>19272</td>\n      <td>alright ChatGPT AI pretty neat @nocontextvarg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18427</td>\n      <td>18427</td>\n      <td>find Microsoft 365 answer ChatGPT successful m...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('num_labels').describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T05:55:12.362715600Z",
     "start_time": "2023-12-29T05:55:12.308760300Z"
    }
   },
   "id": "ecb566c373e9d5ac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train_test split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac1df25269c5ba51"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.processed_tweets,\n",
    "    df.num_labels,\n",
    "    test_size=0.2,\n",
    "    stratify=df.num_labels,\n",
    "    random_state=42\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T05:56:35.342440100Z",
     "start_time": "2023-12-29T05:56:34.721013900Z"
    }
   },
   "id": "9d39b951a397de44"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "preprocess_url = \"https://kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3\"\n",
    "\n",
    "encoder_url = \"https://kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-l-12-h-768-a-12/versions/3\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T06:21:39.423884100Z",
     "start_time": "2023-12-29T06:21:39.409346100Z"
    }
   },
   "id": "2f12be14b4a2b65a"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Op type not registered 'CaseFoldUTF8' in binary running on RAIYAN. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4201\u001B[0m, in \u001B[0;36mGraph._get_op_def\u001B[1;34m(self, type)\u001B[0m\n\u001B[0;32m   4200\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 4201\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_op_def_cache\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m   4202\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n",
      "\u001B[1;31mKeyError\u001B[0m: 'CaseFoldUTF8'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mNotFoundError\u001B[0m                             Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:930\u001B[0m, in \u001B[0;36mload_partial\u001B[1;34m(export_dir, filters, tags, options)\u001B[0m\n\u001B[0;32m    929\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 930\u001B[0m   loader \u001B[38;5;241m=\u001B[39m \u001B[43mLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobject_graph_proto\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msaved_model_proto\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexport_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    931\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mckpt_options\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    932\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mNotFoundError \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:154\u001B[0m, in \u001B[0;36mLoader.__init__\u001B[1;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001B[0m\n\u001B[0;32m    152\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_export_dir \u001B[38;5;241m=\u001B[39m export_dir\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_concrete_functions \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 154\u001B[0m     \u001B[43mfunction_deserialization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_function_def_library\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlibrary\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmeta_graph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgraph_def\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlibrary\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43msaved_object_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_proto\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwrapper_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_WrapperFunction\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    158\u001B[0m \u001B[38;5;66;03m# Store a set of all concrete functions that have been set up with\u001B[39;00m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;66;03m# captures.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:416\u001B[0m, in \u001B[0;36mload_function_def_library\u001B[1;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001B[0m\n\u001B[0;32m    415\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m graph\u001B[38;5;241m.\u001B[39mas_default():\n\u001B[1;32m--> 416\u001B[0m   func_graph \u001B[38;5;241m=\u001B[39m \u001B[43mfunction_def_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_def_to_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    417\u001B[0m \u001B[43m      \u001B[49m\u001B[43mfdef\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    418\u001B[0m \u001B[43m      \u001B[49m\u001B[43mstructured_input_signature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstructured_input_signature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    419\u001B[0m \u001B[43m      \u001B[49m\u001B[43mstructured_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstructured_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    420\u001B[0m \u001B[38;5;66;03m# Restores gradients for function-call ops (not the same as ops that use\u001B[39;00m\n\u001B[0;32m    421\u001B[0m \u001B[38;5;66;03m# custom gradients)\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py:82\u001B[0m, in \u001B[0;36mfunction_def_to_graph\u001B[1;34m(fdef, structured_input_signature, structured_outputs, input_shapes)\u001B[0m\n\u001B[0;32m     80\u001B[0m         input_shapes\u001B[38;5;241m.\u001B[39mappend(input_shape)\n\u001B[1;32m---> 82\u001B[0m graph_def, nested_to_flat_tensor_name \u001B[38;5;241m=\u001B[39m \u001B[43mfunction_def_to_graph_def\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     83\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfdef\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_shapes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m func_graph\u001B[38;5;241m.\u001B[39mas_default():\n\u001B[0;32m     86\u001B[0m   \u001B[38;5;66;03m# Add all function nodes to the graph.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py:252\u001B[0m, in \u001B[0;36mfunction_def_to_graph_def\u001B[1;34m(fdef, input_shapes)\u001B[0m\n\u001B[0;32m    251\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 252\u001B[0m   op_def \u001B[38;5;241m=\u001B[39m \u001B[43mdefault_graph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_op_def\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode_def\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    254\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m attr \u001B[38;5;129;01min\u001B[39;00m op_def\u001B[38;5;241m.\u001B[39mattr:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4205\u001B[0m, in \u001B[0;36mGraph._get_op_def\u001B[1;34m(self, type)\u001B[0m\n\u001B[0;32m   4204\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_c_graph\u001B[38;5;241m.\u001B[39mget() \u001B[38;5;28;01mas\u001B[39;00m c_graph:\n\u001B[1;32m-> 4205\u001B[0m   \u001B[43mpywrap_tf_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTF_GraphGetOpDef\u001B[49m\u001B[43m(\u001B[49m\u001B[43mc_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_bytes\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4206\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mbuf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4207\u001B[0m data \u001B[38;5;241m=\u001B[39m pywrap_tf_session\u001B[38;5;241m.\u001B[39mTF_GetBuffer(buf)\n",
      "\u001B[1;31mNotFoundError\u001B[0m: Op type not registered 'CaseFoldUTF8' in binary running on RAIYAN. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m bert_preprocess_model \u001B[38;5;241m=\u001B[39m \u001B[43mhub\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mKerasLayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreprocess_url\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:157\u001B[0m, in \u001B[0;36mKerasLayer.__init__\u001B[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001B[0m\n\u001B[0;32m    153\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_shape \u001B[38;5;241m=\u001B[39m data_structures\u001B[38;5;241m.\u001B[39mNoDependency(\n\u001B[0;32m    154\u001B[0m       _convert_nest_to_shapes(output_shape))\n\u001B[0;32m    156\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_options \u001B[38;5;241m=\u001B[39m load_options\n\u001B[1;32m--> 157\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_func \u001B[38;5;241m=\u001B[39m \u001B[43mload_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_hub_module_v1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_func, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_is_hub_module_v1\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    160\u001B[0m \u001B[38;5;66;03m# Update with the defaults when using legacy TF1 Hub format.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:459\u001B[0m, in \u001B[0;36mload_module\u001B[1;34m(handle, tags, load_options)\u001B[0m\n\u001B[0;32m    457\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:  \u001B[38;5;66;03m# Expected before TF2.4.\u001B[39;00m\n\u001B[0;32m    458\u001B[0m       set_load_options \u001B[38;5;241m=\u001B[39m load_options\n\u001B[1;32m--> 459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodule_v2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mset_load_options\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_hub\\module_v2.py:120\u001B[0m, in \u001B[0;36mload\u001B[1;34m(handle, tags, options)\u001B[0m\n\u001B[0;32m    117\u001B[0m   obj \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39msaved_model\u001B[38;5;241m.\u001B[39mload_v2(\n\u001B[0;32m    118\u001B[0m       module_path, tags\u001B[38;5;241m=\u001B[39mtags, options\u001B[38;5;241m=\u001B[39moptions)\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 120\u001B[0m   obj \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mv1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msaved_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_v2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    121\u001B[0m obj\u001B[38;5;241m.\u001B[39m_is_hub_module_v1 \u001B[38;5;241m=\u001B[39m is_hub_module_v1  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:800\u001B[0m, in \u001B[0;36mload\u001B[1;34m(export_dir, tags, options)\u001B[0m\n\u001B[0;32m    798\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(export_dir, os\u001B[38;5;241m.\u001B[39mPathLike):\n\u001B[0;32m    799\u001B[0m   export_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(export_dir)\n\u001B[1;32m--> 800\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mload_partial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexport_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mroot\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    801\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:933\u001B[0m, in \u001B[0;36mload_partial\u001B[1;34m(export_dir, filters, tags, options)\u001B[0m\n\u001B[0;32m    930\u001B[0m   loader \u001B[38;5;241m=\u001B[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001B[0;32m    931\u001B[0m                   ckpt_options, options, filters)\n\u001B[0;32m    932\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mNotFoundError \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m--> 933\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\n\u001B[0;32m    934\u001B[0m       \u001B[38;5;28mstr\u001B[39m(err) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m You may be trying to load on a different device \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    935\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom the computational device. Consider setting the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    936\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    937\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto the io_device such as \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/job:localhost\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    938\u001B[0m root \u001B[38;5;241m=\u001B[39m loader\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    939\u001B[0m root\u001B[38;5;241m.\u001B[39mgraph_debug_info \u001B[38;5;241m=\u001B[39m loader\u001B[38;5;241m.\u001B[39madjust_debug_info_func_names(debug_info)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: Op type not registered 'CaseFoldUTF8' in binary running on RAIYAN. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
     ]
    }
   ],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(preprocess_url)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T06:21:42.000658700Z",
     "start_time": "2023-12-29T06:21:41.535305800Z"
    }
   },
   "id": "7a9f7ff84cfe3841"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1dd3f7193ad58961"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
