{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-04T15:06:50.525378300Z",
     "start_time": "2024-01-04T15:06:41.974783400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   num_labels                                   processed_tweets\n0           1      alright ChatGPT AI pretty neat @nocontextvarg\n1           1  ok definitely go replace soon importantly chat...\n2           0  ask chatgpt explain 4 famous chess quote Timma...\n3           1                               chatgpt popular good\n4           0  write ida plugin query chatgpt explain decompi...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num_labels</th>\n      <th>processed_tweets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>alright ChatGPT AI pretty neat @nocontextvarg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>ok definitely go replace soon importantly chat...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>ask chatgpt explain 4 famous chess quote Timma...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>chatgpt popular good</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>write ida plugin query chatgpt explain decompi...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Python Codes\\Code\\Code\\ChatGPT-sentiment-analysis\\processed_file.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 2)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T15:06:52.263654700Z",
     "start_time": "2024-01-04T15:06:52.234754400Z"
    }
   },
   "id": "2f37d9c3c32e1e92"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "num_labels          0\nprocessed_tweets    8\ndtype: int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T15:06:53.196808600Z",
     "start_time": "2024-01-04T15:06:53.180050500Z"
    }
   },
   "id": "488e4dfd31b58804"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "3718"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T15:06:59.484591700Z",
     "start_time": "2024-01-04T15:06:59.454636600Z"
    }
   },
   "id": "88d0b34662704201"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = df.dropna().drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T15:07:00.556124900Z",
     "start_time": "2024-01-04T15:07:00.501654700Z"
    }
   },
   "id": "b3cbc0584b7f104d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "           processed_tweets         \\\n                      count unique   \nnum_labels                           \n0                     18581  18581   \n1                     19272  19272   \n2                     18427  18427   \n\n                                                                    \n                                                          top freq  \nnum_labels                                                          \n0           ask chatgpt explain 4 famous chess quote Timma...    1  \n1               alright ChatGPT AI pretty neat @nocontextvarg    1  \n2           find Microsoft 365 answer ChatGPT successful m...    1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">processed_tweets</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n    </tr>\n    <tr>\n      <th>num_labels</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18581</td>\n      <td>18581</td>\n      <td>ask chatgpt explain 4 famous chess quote Timma...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19272</td>\n      <td>19272</td>\n      <td>alright ChatGPT AI pretty neat @nocontextvarg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18427</td>\n      <td>18427</td>\n      <td>find Microsoft 365 answer ChatGPT successful m...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('num_labels').describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T15:07:02.648204100Z",
     "start_time": "2024-01-04T15:07:02.576968Z"
    }
   },
   "id": "ecb566c373e9d5ac"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "   num_labels                                   processed_tweets  len_of_text\n0           1      alright ChatGPT AI pretty neat @nocontextvarg           45\n1           1  ok definitely go replace soon importantly chat...          147\n2           0  ask chatgpt explain 4 famous chess quote Timma...          116\n3           1                               chatgpt popular good           20\n4           0  write ida plugin query chatgpt explain decompi...          126",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num_labels</th>\n      <th>processed_tweets</th>\n      <th>len_of_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>alright ChatGPT AI pretty neat @nocontextvarg</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>ok definitely go replace soon importantly chat...</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>ask chatgpt explain 4 famous chess quote Timma...</td>\n      <td>116</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>chatgpt popular good</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>write ida plugin query chatgpt explain decompi...</td>\n      <td>126</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['len_of_text'] = df.processed_tweets.apply(lambda x: len(x))\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T15:15:51.647873Z",
     "start_time": "2024-01-04T15:15:51.602087Z"
    }
   },
   "id": "e3fcd46b6c9a504a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "280"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.len_of_text.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T15:16:08.962548Z",
     "start_time": "2024-01-04T15:16:08.941895200Z"
    }
   },
   "id": "127468c04ad51c1b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train_test split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac1df25269c5ba51"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.processed_tweets,\n",
    "    df.num_labels,\n",
    "    test_size=0.2,\n",
    "    stratify=df.num_labels,\n",
    "    random_state=42\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T15:16:25.789029600Z",
     "start_time": "2024-01-04T15:16:24.449057500Z"
    }
   },
   "id": "9d39b951a397de44"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# try from kaggle"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "198e7c1e1fdfbbd0"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T15:16:32.355632900Z",
     "start_time": "2024-01-04T15:16:31.201434500Z"
    }
   },
   "id": "dde095baa7a2c77d"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "features = df.processed_tweets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T15:16:34.941792500Z",
     "start_time": "2024-01-04T15:16:34.898615500Z"
    }
   },
   "id": "f8b7bb87dcc95fd3"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "labels = df.num_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T15:16:35.538501900Z",
     "start_time": "2024-01-04T15:16:35.509669800Z"
    }
   },
   "id": "3e217995e032cd24"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "classifier = keras_nlp.models.BertClassifier.from_preset(\n",
    "    \"bert_base_en\",\n",
    "    num_classes=3,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T15:16:44.883153100Z",
     "start_time": "2024-01-04T15:16:36.266833Z"
    }
   },
   "id": "8791d743c4785e05"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall' defined at (most recent call last):\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1077, in launch_instance\n      app.start()\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n      super().run_forever()\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\raiya\\AppData\\Local\\Temp\\ipykernel_12092\\3817554648.py\", line 1, in <module>\n      history = classifier.fit(\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\keras_nlp\\src\\utils\\pipeline_model.py\", line 201, in fit\n      return super().fit(\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\nNode: 'StatefulPartitionedCall'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_train_function_24983]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInternalError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\n\u001B[0;32m      5\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\keras_nlp\\src\\utils\\pipeline_model.py:201\u001B[0m, in \u001B[0;36mPipelineModel.fit\u001B[1;34m(self, x, y, batch_size, sample_weight, validation_data, validation_split, **kwargs)\u001B[0m\n\u001B[0;32m    194\u001B[0m         (vx, vy, vsw) \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39munpack_x_y_sample_weight(\n\u001B[0;32m    195\u001B[0m             validation_data\n\u001B[0;32m    196\u001B[0m         )\n\u001B[0;32m    197\u001B[0m         validation_data \u001B[38;5;241m=\u001B[39m _convert_inputs_to_dataset(\n\u001B[0;32m    198\u001B[0m             vx, vy, vsw, batch_size\n\u001B[0;32m    199\u001B[0m         )\n\u001B[1;32m--> 201\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mfit(\n\u001B[0;32m    202\u001B[0m     x\u001B[38;5;241m=\u001B[39mx,\n\u001B[0;32m    203\u001B[0m     y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    204\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    205\u001B[0m     sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    206\u001B[0m     validation_data\u001B[38;5;241m=\u001B[39mvalidation_data,\n\u001B[0;32m    207\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    208\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mInternalError\u001B[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall' defined at (most recent call last):\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1077, in launch_instance\n      app.start()\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n      super().run_forever()\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\raiya\\AppData\\Local\\Temp\\ipykernel_12092\\3817554648.py\", line 1, in <module>\n      history = classifier.fit(\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\keras_nlp\\src\\utils\\pipeline_model.py\", line 201, in fit\n      return super().fit(\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\raiya\\anaconda3\\envs\\dl_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\nNode: 'StatefulPartitionedCall'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_train_function_24983]"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(\n",
    "    x = features,\n",
    "    y = labels,\n",
    "    batch_size=2\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T15:17:22.508810800Z",
     "start_time": "2024-01-04T15:16:47.314411700Z"
    }
   },
   "id": "db6f31f7911f23af"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
